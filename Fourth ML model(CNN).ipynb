{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTwCLES0nbkhLjmt8c4eYz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greapis/jaeha-shim/blob/main/Fourth%20ML%20model(CNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7rYdRtg0EGMV"
      },
      "outputs": [],
      "source": [
        "## 컨볼루션을 통한 컴퓨터 비전의 정확성 개선\n",
        "\n",
        "# 이제 심층 신경망(DNN)을 사용하여 입력 레이어(입력 데이터 모양)와\n",
        "# 히든 레이어의 세 가지 레이어로 구성된 패션 이미지 인식을 수행하는 방법을 알게 되었습니다.\n",
        "\n",
        "# 히든 레이어의 크기, 학습 세대의 수와 같이 최종 정확성에 영향을 주는 여러 매개변수를 실험했습니다.\n",
        "\n",
        "# 편의를 위해 전체 코드를 다시 보내드립니다. 이를 실행하고 끝에 출력된 테스트 정확성을 기록해 둡니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print('Test loss: {}, Test accuracy: {}'.format(test_loss, test_accuracy*100))\n",
        "\n",
        "# 컨볼루션을 사용하면 이미지의 내용을 좁혀 구체적인 세부정보에 초점을 맞출 수 있습니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-mrWVn4t1LB",
        "outputId": "fdd1b440-b392-4b35-c63f-cdb85b5911f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.5019 - accuracy: 0.8237\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3735 - accuracy: 0.8657\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3370 - accuracy: 0.8755\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3137 - accuracy: 0.8852\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2948 - accuracy: 0.8899\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8778\n",
            "Test loss: 0.34208306670188904, Test accuracy: 87.77999877929688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. 코드 사용해 보기\n",
        "# 다음 코드를 실행합니다. 이전의 신경망과 동일하지만 이번에는 컨볼루셔널 레이어가 먼저 추가됩니다.\n",
        "# 시간이 좀 더 걸리지만 정확성에 미치는 영향을 살펴봅니다.\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images = training_images.reshape(60000, 28, 28, 1)\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation ='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print('Test loss: {}, Test accuracy: {}'.format(test_loss, test_accuracy*100))\n",
        "\n",
        "# 학습 데이터에 대해 약 93%, 검증 데이터에서 약 91% 의 상승 효과를 보였습니다.\n",
        "\n",
        "# 이제 더 많은 에포크 동안(예: 20개 정도) 결과를 실행해 보세요.\n",
        "# 학습 결과는 매우 좋아 보일 수 있지만 과적합이라는 현상으로 인해 유효성 검사 결과가 실제로 낮아질 수 있습니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMcQWsCqysJ2",
        "outputId": "822c5689-4fe8-4d79-e30a-990debdd4ac5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               204928    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 243786 (952.29 KB)\n",
            "Trainable params: 243786 (952.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 87s 46ms/step - loss: 0.4458 - accuracy: 0.8374\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 85s 45ms/step - loss: 0.2986 - accuracy: 0.8897\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.2500 - accuracy: 0.9078\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 83s 44ms/step - loss: 0.2207 - accuracy: 0.9176\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.1922 - accuracy: 0.9276\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2578 - accuracy: 0.9088\n",
            "Test loss: 0.2578303813934326, Test accuracy: 90.88000059127808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. 데이터 수집\n",
        "# 첫 번째 단계는 데이터를 수집하는 것입니다.\n",
        "\n",
        "# 여기서 달라진 부분과 학습 데이터를 다시 구성하는 데 필요한 학습 데이터가 있음을 알 수 있습니다.\n",
        "# 첫 번째 컨볼루션에서는 모든 것을 포함하는 단일 텐서가 예상되므로,\n",
        "# 목록에 있는 20x28x1 항목 60,000개 대신 60,000x28x28x1인 테스트용 단일 4D 목록이 있습니다.\n",
        "# 이렇게 하지 않으면 컨볼루션이 모양을 인식하지 못하므로 학습할 때 오류가 발생합니다.\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_image, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images = training_images.reshape(60000, 28, 28, 1)\n",
        "training_image = training_images/255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images/255.0"
      ],
      "metadata": {
        "id": "d_54zCRcF8Lg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. 모델 정의**\n",
        "\n",
        "다음으로 모델을 정의합니다.\n",
        "상단의 입력 레이어 대신 컨볼루셔널 레이어를 추가합니다. 사용할 수 있는 매개변수는 다음과 같습니다.\n",
        "\n",
        "\n",
        "\n",
        "*  생성하려는 컨볼루션의 수입니다. 32와 같은 값은 좋은 출발점입니다.\n",
        "*  컨볼루셔널 행렬의 크기(이 경우 3x3 그리드)\n",
        "\n",
        "\n",
        "*  사용할 활성화 함수입니다. 이 경우에는 relu를 사용합니다.\n",
        "*  첫 번째 레이어에서 입력 데이터의 모양입니다.\n",
        "\n",
        "\n",
        "컨볼루션에서 이어지는 컨볼루션입니다. 컨볼루션에서 강조된 특징의 콘텐츠를 유지하면서 이미지를 압축하도록 설계된 최대 풀링 레이어가 있습니다. 최대 풀링에 최대 (2,2)를 지정하면 이미지 크기가 4의 배수로 감소하는 효과가 있습니다. 2x2 픽셀의 배열과 가장 큰 픽셀 값을 선택하여 4픽셀을 1로 변환합니다. 이미지 전체에 걸쳐 이 계산을 반복하므로 가로 픽셀 수를 절반으로 줄이고 세로 픽셀 수는 절반으로 줄입니다.\n",
        "\n",
        "\n",
        "model.summary()를 호출하여 네트워크의 크기와 모양을 확인할 수 있습니다. 모든 최대 풀링 레이어 후에 이미지 크기가 다음과 같이 감소합니다.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s2K1w_Qi5XE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "3fp-Dz_f6RIx",
        "outputId": "091b88cc-33b7-416b-c98e-a537a2c910d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               204928    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 243786 (952.29 KB)\n",
            "Trainable params: 243786 (952.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN의 전체 코드는 다음과 같습니다.\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # Add another convolution\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # Now flatten the output. After the you will just have the same DNN structure as the non convolutional version\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # The same 128 dense layers, and 10 output layers as in the pre-convolution example:\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "kqleCGgEEg8T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. 모델 컴파일 및 학습**\n",
        "\n",
        "모델을 컴파일하고 적합성 메서드를 호출하여 학습을 진행하고 테스트 세트에서 손실 및 정확성을 평가합니다."
      ],
      "metadata": {
        "id": "FAS_VlVSIieh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test loss: {}, Test accuracy: {}'.format(test_loss, test_acc*100))\n",
        "\n",
        "\n",
        "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.fit(training_images, training_labels, epochs=5)\n",
        "# test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "# print ('Test loss: {}, Test accuracy: {}'.format(test_loss, test_acc*100))"
      ],
      "metadata": {
        "id": "bxsgYqbEGIYG",
        "outputId": "d30b843b-d2e5-4857-dca1-70aca0adfb59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 54s 28ms/step - loss: 0.4445 - accuracy: 0.8376\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.3005 - accuracy: 0.8903\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 76s 40ms/step - loss: 0.2556 - accuracy: 0.9050\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 65s 34ms/step - loss: 0.2227 - accuracy: 0.9170\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 67s 36ms/step - loss: 0.1961 - accuracy: 0.9258\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2756 - accuracy: 0.9014\n",
            "Test loss: 0.27558115124702454, Test accuracy: 90.14000296592712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. 컨볼루션 및 풀링 시각화**\n",
        "\n",
        "\n",
        "이 코드는 컨볼루션을 그래픽으로 보여줍니다. print (test_labels[:100])는 테스트 세트의 처음 100개 라벨을 나타내며 색인 0, 색인 23 및 색인 28의 라벨이 모두 동일한 값 (9)이라는 것을 확인할 수 있습니다. 모든 신발이요. 각각에서 컨볼루션을 진행한 결과를 살펴보겠습니다. 각 컨볼루션에서 공통 특성이 나타나기 시작합니다. DNN은 이 데이터에 대해 학습할 때 더 적은 정보로 학습하며 컨볼루션 및 풀링 조합에 따라 신발 간에 공통점을 찾을 수 있습니다."
      ],
      "metadata": {
        "id": "K7Nnzv0rOrI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels[:100])"
      ],
      "metadata": {
        "id": "6PX5BUWXMQS0",
        "outputId": "126afb78-34f5-45cc-e4d7-eec3eeb9645f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 이러한 라벨에 해당하는 이미지 중 일부를 선택하고 컨볼루션을 거치는 동안 이러한 이미지를 렌더링할 수 있습니다. 따라서 다음 코드에서 FIRST_IMAGE, SECOND_IMAGE, THIRD_IMAGE는 모두 발목 부츠 9의 색인입니다."
      ],
      "metadata": {
        "id": "1kYT35WdO8QJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, axarr = plt.subplots(3,4)\n",
        "FIRST_IMAGE = 0\n",
        "SECOND_IMAGE = 23\n",
        "THIRD_IMAGE = 28\n",
        "CONVOLUTION_NUMBER = 6\n",
        "from tensorflow.keras import models\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
        "for x in range(0, 4):\n",
        "  f1 = activation_model.predict(test_images[FIRTS_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[0,x].imshow\n",
        "\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# f, axarr = plt.subplots(3,4)\n",
        "# FIRST_IMAGE=0\n",
        "# SECOND_IMAGE=23\n",
        "# THIRD_IMAGE=28\n",
        "# CONVOLUTION_NUMBER = 6\n",
        "# from tensorflow.keras import models\n",
        "# layer_outputs = [layer.output for layer in model.layers]\n",
        "# activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
        "# for x in range(0,4):\n",
        "#   f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "#   axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "#   axarr[0,x].grid(False)\n",
        "#   f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "#   axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "#   axarr[1,x].grid(False)\n",
        "#   f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "#   axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "#   axarr[2,x].grid(False)"
      ],
      "metadata": {
        "id": "YbR0E4QBO1HL"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}